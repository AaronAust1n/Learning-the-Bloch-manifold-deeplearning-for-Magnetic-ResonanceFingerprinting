{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqe2u5u5zhMj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: matplotlib in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15 in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\apps\\anaconda3\\envs\\gpu-cuda10\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "VIE7-SAqir7O",
    "outputId": "2b6972e1-a573-4505-d544-690a1d68fbc8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRWp8xWFEijO"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir(\"/content/drive/My Drive\") \n",
    "import ra\n",
    "#import complexLayers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-BK2JMPjju-"
   },
   "outputs": [],
   "source": [
    "dataset = ra.read('atomsroa.ra')\n",
    "train_data = torch.tensor(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.imag\n",
    "train_data =  torch.transpose(train_data, 0, 1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelset = ra.read('paramsroa.ra')\n",
    "train_label1 = torch.tensor(labelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = ra.read('atoms.ra')\n",
    "traindata1 = torch.tensor(dataset1)\n",
    "traindata1 = traindata1.imag\n",
    "traindata1 =  torch.transpose(traindata1, 0, 1).unsqueeze(1)\n",
    "label1 = ra.read('params.ra')\n",
    "label1 = torch.tensor(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0038,  0.0015, -0.0007,  ..., -0.0274, -0.0272, -0.0269]],\n",
      "\n",
      "        [[ 0.0045,  0.0023,  0.0001,  ..., -0.0279, -0.0276, -0.0273]],\n",
      "\n",
      "        [[ 0.0052,  0.0031,  0.0010,  ..., -0.0283, -0.0280, -0.0278]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0215,  0.0229,  0.0242,  ..., -0.0250, -0.0246, -0.0243]],\n",
      "\n",
      "        [[ 0.0216,  0.0230,  0.0243,  ..., -0.0250, -0.0246, -0.0243]],\n",
      "\n",
      "        [[ 0.0216,  0.0230,  0.0243,  ..., -0.0250, -0.0247, -0.0243]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[[-0.0100, -0.0114, -0.0094,  ...,  0.0324,  0.0322,  0.0320]],\n",
      "\n",
      "        [[-0.0105, -0.0123, -0.0106,  ...,  0.0329,  0.0327,  0.0325]],\n",
      "\n",
      "        [[-0.0110, -0.0132, -0.0117,  ...,  0.0333,  0.0331,  0.0330]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0141, -0.0290, -0.0443,  ...,  0.0006,  0.0012,  0.0019]],\n",
      "\n",
      "        [[-0.0141, -0.0290, -0.0443,  ...,  0.0006,  0.0012,  0.0019]],\n",
      "\n",
      "        [[-0.0141, -0.0289, -0.0443,  ...,  0.0006,  0.0012,  0.0019]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(traindata1)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([108056, 1, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([108056, 1, 1000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(traindata1.shape)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alldata = torch.cat((train_data,traindata1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = torch.cat((train_label1[:-1,:],label1[:-1,:]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(labels1)\n",
    "print(labels1.shape)\n",
    "print(train_label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([216112, 2])\n"
     ]
    }
   ],
   "source": [
    "labels1 = torch.transpose(labels1, 0, 1)\n",
    "print(labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "train_dataset = data.TensorDataset(alldata,labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtO2l_0K9bVo"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_reduced = PCA(n_components=10).fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "9jhCmOGlzHuJ",
    "outputId": "d404eff5-582b-40af-8ba4-2f163944744e"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(train_data)\n",
    "\n",
    "print(pca.explained_variance_ratio_.shape)\n",
    "print(pca.components_.shape)\n",
    "print(pca.singular_values_.shape)\n",
    "print(pca.mean_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyEh1FCOM4gT"
   },
   "outputs": [],
   "source": [
    "train_data = torch.tensor(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ih21UQILm0Hl"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [140000, 60000 ,16112])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the network model with smallest\n",
    "average error for validation data consists of 3 convolutional layers (kernel size = 3, stride\n",
    "size = 2), each followed by a rectified linear unit (ReLU) activation function. The number\n",
    "of the feature maps per convolutional layer is increasing, from 32 in the first to 128 in\n",
    "the last. After convolution an average pooling layer follows with the same size as the\n",
    "stride size. The last layer is fully connected, with 2 outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahjQ0hXkj6Yl"
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            #nn.Dropout(),\n",
    "            nn.Linear(36, 18),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(),\n",
    "            nn.Linear(18, 9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(9, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3pzehZtrCEC"
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "val_loss = list()\n",
    "#val_accu = list()\n",
    "train_loss = list()\n",
    "#train_accu = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert torch.cuda.is_available()\n",
    "device1 = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#cuda_device = torch.device(\"cuda\")\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "trainloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "validloader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    outputs = model(xb.float())\n",
    "    yb = yb.float()\n",
    "    outputs = torch.squeeze(outputs, 1)\n",
    "    loss = loss_func(outputs, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycuda\n",
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sGAHKMREJzYA",
    "outputId": "e1d97095-19c2-490c-dd04-c3932fe2ce54"
   },
   "outputs": [],
   "source": [
    "\n",
    "# build the model\n",
    "model = AlexNet().to(device1)\n",
    "\n",
    "# define the loss function and the optimiser\n",
    "loss_function = nn.MSELoss()\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "\n",
    "# the epoch loop\n",
    "for epoch in range(N):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    loss=0\n",
    "    for data in trainloader:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        #inputs = inputs.unsqueeze(1).unsqueeze(-1)\n",
    "        #inputs = inputs.unsqueeze(1)\n",
    "        #inputs = torch.unsqueeze(inputs1, 2)\n",
    "\n",
    "        inputs, labels = inputs.to(device1), labels.to(device1)\n",
    "        \n",
    "        \n",
    "        loss, nums = loss_batch(model, loss_function, inputs.float(), labels.float(), optimiser)\n",
    "        running_loss += loss\n",
    "    train_loss.append(loss)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, nums = zip(\n",
    "                *[loss_batch(model.to(device1), loss_function, xb.to(device1), yb.to(device1)) for xb, yb in validloader]\n",
    "            )\n",
    "        val_loss1 = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        val_loss.append(val_loss1)\n",
    "\n",
    "\n",
    "        #print(epoch, val_loss)\n",
    "\n",
    "        \n",
    "        # keep track of the loss this epoch\n",
    "        #running_loss += loss.item()\n",
    "    print(\"Epoch %d, loss %4.2f\" % (epoch, running_loss))\n",
    "print('**** Finished Training ****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "RrXkmLWusgWY",
    "outputId": "94727097-6aee-4d73-97d6-e8cc99f69d52",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(0, N)\n",
    "y1 = train_loss\n",
    "#y2 = train_accu\n",
    "y3 = val_loss\n",
    "#y4 = val_accu\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x, y1, 'o-')\n",
    "plt.title('train_loss and train_accu')\n",
    "plt.ylabel('train_loss')\n",
    "#plt.subplot(2, 1, 2)\n",
    "#plt.plot(x, y2, '.-')\n",
    "#plt.xlabel('epoches')\n",
    "#plt.ylabel('train_accu')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x, y3, 'o-')\n",
    "plt.ylabel('val_loss')\n",
    "#plt.subplot(2, 2, 2)\n",
    "#plt.plot(x, y4, '.-')\n",
    "#plt.title('val_loss and val_accu')\n",
    "#lt.ylabel('val_accu')\n",
    "plt.show()\n",
    "#plt.savefig(\"accuracy_loss.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "5Qg7Iyg-RsZc",
    "outputId": "6e257a36-b10f-4d83-ebab-7bce690bf17c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = list()\n",
    "for data in testloader:\n",
    "    losses, nums = zip(\n",
    "                *[loss_batch(model.to(device1), loss_function, xb.to(device1), yb.to(device1)) for xb, yb in testloader])\n",
    "    test_loss1 = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "    test_loss.append(test_loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.467445583779146, 17.467445481498288, 17.467445536426897, 17.467445456875115, 17.467445589461416, 17.467445526956446, 17.467445587567326, 17.467445526956446, 17.467445727729988, 17.467445568626427, 17.467445682271826, 17.467445633025488, 17.467445572414608, 17.467445566732337, 17.467445417099228, 17.467445558208933, 17.467445456875115, 17.467445646284116, 17.467445522221222, 17.467445631131397, 17.467445617872766, 17.467445451192848, 17.467445634919578, 17.467445557261886, 17.467445420887405, 17.467445509909638, 17.467445646284116, 17.46744556957347, 17.467445528850536, 17.467445589461416, 17.467445559155976, 17.467445553473706, 17.467445436040126, 17.467445502333277, 17.467445574308698, 17.467445604614138, 17.467445472027837, 17.467445481498288, 17.467445459716252, 17.46744556767938, 17.467445436040126, 17.467445489074645, 17.467445509909638, 17.467445487180555, 17.467445608402315, 17.467445417099228, 17.467445398158326, 17.467445591355506, 17.467445612190495, 17.467445487180555, 17.46744560745527, 17.467445418993318, 17.46744563870776, 17.467445468239656, 17.467445445510577, 17.467445483392375, 17.467445610296405, 17.467445461610343, 17.467445422781495, 17.467445454981025, 17.467445490968736, 17.467445506121457, 17.467445536426897, 17.467445580938012, 17.467445483392375, 17.467445483392375, 17.467445614084586, 17.467445538320987, 17.467445369746976, 17.467445615031632, 17.467445572414608, 17.467445579990965, 17.467445612190495, 17.467445623555037, 17.467445526956446, 17.467445439828307, 17.467445470133747, 17.467445481498288, 17.467445449298758, 17.467445579990965, 17.467445653860477, 17.467445615978676, 17.467445513697818, 17.46744559798482, 17.467445581885055, 17.467445509909638, 17.467445509909638, 17.467445483392375, 17.467445549685525, 17.467445544003258, 17.467445526956446, 17.467445502333277, 17.467445485286465, 17.467445587567326, 17.467445680377736, 17.467445430357856, 17.467445555367796, 17.467445595143687, 17.467445538320987, 17.467445591355506, 17.467445557261886, 17.467445559155976, 17.467445568626427, 17.467445631131397, 17.467445464451476, 17.467445633025488, 17.467445542109168, 17.467445517485995, 17.467445597037777, 17.467445640601845, 17.467445589461416, 17.467445519380085, 17.467445490968736, 17.467445515591905, 17.467445544003258, 17.467445519380085, 17.467445485286465, 17.467445631131397, 17.467445544003258, 17.467445648178206, 17.467445559155976, 17.467445369746976, 17.46744563397253, 17.467445615978676, 17.467445536426897, 17.467445545897345]\n"
     ]
    }
   ],
   "source": [
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, 126)\n",
    "y3 = test_loss\n",
    "plt.plot(x, y3, 'o-')\n",
    "plt.title('test_loss')\n",
    "plt.ylabel('test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eDZ_0FSIRz4A",
    "outputId": "6127c2c9-dc3b-4994-a315-27d714d4f9ac"
   },
   "outputs": [],
   "source": [
    "for data in testloader:\n",
    "    inputs, lablels = data\n",
    "    predictions = model(inputs.float())\n",
    "    loss = loss_function(predictions,labels)\n",
    "    loss = loss/128\n",
    "    print(\"loss\",loss)\n",
    "    print(\"predicted parameter:\", predictions)\n",
    "    print(\"setting parameter:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = ra.read('atomsroa.ra')\n",
    "testdata = torch.tensor(testdataset)\n",
    "testdata = testdata.imag\n",
    "label1 = ra.read('paramsroa.ra')\n",
    "label1 = torch.tensor(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0xuJReg8EbA"
   },
   "outputs": [],
   "source": [
    "for i in range(8056):\n",
    "    inputs = testdata[:,i]\n",
    "    lablels = label1[0,i]\n",
    "    predictions = model(inputs.float())\n",
    "\n",
    "    print(\"predicted parameter:\", predictions)\n",
    "    print(\"setting parameter:\", lablels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98SN3jbBbQPo"
   },
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AC85zIKAbLgu"
   },
   "source": [
    "Being able to train a model is fine, but in practice once we've trained the model we probably want to save the result so we can reuse it at a later time. PyTorch makes saving the model easy using the torch.save(state, filepath) function. This will save the weights of the model so they can be loaded into a new instance at a later point.\n",
    "\n",
    "Run the following code to save the weights for use in the next part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYwWauk6a7vK"
   },
   "outputs": [],
   "source": [
    "#save the trained model weights\n",
    "torch.save(model.state_dict(), \"./Alexnet.weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3755E9cbClj"
   },
   "source": [
    "If you are running on Colab, run the following to download the weights to the local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "YQso-4fca_mI",
    "outputId": "b059fe76-e584-437c-f499-8ca3da61d6d5"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('BaselineModel.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AzH-0Wu9brJG",
    "outputId": "68c73ea4-c60c-4c51-9b54-a278d8492b63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet().to(device1)\n",
    "\n",
    "# define the loss function and the optimiser\n",
    "loss_function = nn.MSELoss()\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "model.load_state_dict(torch.load('Alexnet.weights'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MRF-net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
